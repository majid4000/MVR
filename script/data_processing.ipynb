{"cells":[{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n","Requirement already satisfied: nltk in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (3.8.1)\n","Requirement already satisfied: click in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from nltk) (2024.5.15)\n","Requirement already satisfied: tqdm in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from nltk) (4.66.4)\n","Note: you may need to restart the kernel to use updated packages.\n","Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n","Requirement already satisfied: bs4 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (0.0.2)\n","Requirement already satisfied: beautifulsoup4 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from bs4) (4.12.3)\n","Requirement already satisfied: soupsieve>1.2 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.5)\n","Note: you may need to restart the kernel to use updated packages.\n","Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n","Requirement already satisfied: ipykernel in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (6.29.4)\n","Requirement already satisfied: ipywidgets in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (8.1.3)\n","Requirement already satisfied: emoji in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (2.12.1)\n","Requirement already satisfied: contractions in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (0.1.73)\n","Requirement already satisfied: appnope in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipykernel) (0.1.4)\n","Requirement already satisfied: comm>=0.1.1 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipykernel) (0.2.2)\n","Requirement already satisfied: debugpy>=1.6.5 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipykernel) (1.6.7)\n","Requirement already satisfied: ipython>=7.23.1 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipykernel) (8.12.0)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipykernel) (7.3.4)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipykernel) (5.7.2)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipykernel) (0.1.7)\n","Requirement already satisfied: nest-asyncio in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipykernel) (1.6.0)\n","Requirement already satisfied: packaging in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipykernel) (24.1)\n","Requirement already satisfied: psutil in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipykernel) (5.9.0)\n","Requirement already satisfied: pyzmq>=24 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipykernel) (25.1.2)\n","Requirement already satisfied: tornado>=6.1 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipykernel) (6.1)\n","Requirement already satisfied: traitlets>=5.4.0 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipykernel) (5.14.3)\n","Requirement already satisfied: widgetsnbextension~=4.0.11 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipywidgets) (4.0.11)\n","Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipywidgets) (3.0.11)\n","Requirement already satisfied: typing-extensions>=4.7.0 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from emoji) (4.12.2)\n","Requirement already satisfied: textsearch>=0.0.21 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from contractions) (0.0.24)\n","Requirement already satisfied: backcall in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n","Requirement already satisfied: decorator in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (0.19.1)\n","Requirement already satisfied: pickleshare in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (3.0.47)\n","Requirement already satisfied: pygments>=2.4.0 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (2.18.0)\n","Requirement already satisfied: stack-data in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (0.6.2)\n","Requirement already satisfied: pexpect>4.3 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n","Requirement already satisfied: entrypoints in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel) (0.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0)\n","Requirement already satisfied: platformdirs>=2.5 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.2.2)\n","Requirement already satisfied: anyascii in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n","Requirement already satisfied: pyahocorasick in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n","Requirement already satisfied: wcwidth in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel) (0.2.13)\n","Requirement already satisfied: six>=1.5 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n","Requirement already satisfied: executing>=1.2.0 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.0.1)\n","Requirement already satisfied: asttokens>=2.1.0 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n","Requirement already satisfied: pure-eval in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n","Note: you may need to restart the kernel to use updated packages.\n","Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n","Requirement already satisfied: langdetect in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (1.0.9)\n","Requirement already satisfied: six in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from langdetect) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n","Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n","Collecting pandas\n","  Downloading https://mirrors.aliyun.com/pypi/packages/53/c3/f8e87361f7fdf42012def602bfa2a593423c729f5cb7c97aed7f51be66ac/pandas-2.0.3-cp38-cp38-macosx_11_0_arm64.whl (10.7 MB)\n","\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m540.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from pandas) (2.9.0)\n","Collecting pytz>=2020.1 (from pandas)\n","  Downloading https://mirrors.aliyun.com/pypi/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl (505 kB)\n","\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m552.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n","\u001b[?25hCollecting tzdata>=2022.1 (from pandas)\n","  Downloading https://mirrors.aliyun.com/pypi/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n","\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m544.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n","\u001b[?25hCollecting numpy>=1.20.3 (from pandas)\n","  Downloading https://mirrors.aliyun.com/pypi/packages/a7/ae/f53b7b265fdc701e663fbb322a8e9d4b14d9cb7b2385f45ddfabfc4327e4/numpy-1.24.4-cp38-cp38-macosx_11_0_arm64.whl (13.8 MB)\n","\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m557.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/zhouyf/opt/anaconda3/envs/ml38/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Installing collected packages: pytz, tzdata, numpy, pandas\n","Successfully installed numpy-1.24.4 pandas-2.0.3 pytz-2024.1 tzdata-2024.1\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install nltk\n","%pip install bs4\n","%pip install ipykernel ipywidgets emoji contractions\n","%pip install langdetect\n","%pip install pandas\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /Users/zhouyf/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /Users/zhouyf/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     /Users/zhouyf/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /Users/zhouyf/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]}],"source":["# General Libraries\n","import os\n","import numpy as np\n","from tqdm import tqdm\n","import json\n","\n","import config\n","import pandas as pd\n","\n","# Text Processing and Feature Engineering\n","import re\n","import string\n","import nltk\n","import emoji\n","import contractions\n","from langdetect import detect, LangDetectException\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer, PorterStemmer\n","from nltk.corpus import stopwords\n","\n","\n","# NLTK Download\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","\n","# Enable the notebook extension for tqdm\n","tqdm.pandas()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"sQlDSfVtFBSa"},"outputs":[],"source":["df_gn = pd.read_json(config.googel_news_og)\n","df_sf = pd.read_json(config.stack_overflow_og)\n","df_tw = pd.read_json(config.tweets_og)"]},{"cell_type":"markdown","metadata":{},"source":["# Data Cleaning"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Data Cleaning\n","# Initialize the lemmatizer and stopwords\n","stop_words = set(stopwords.words('english'))\n","lemmatizer = WordNetLemmatizer()\n","\n","# 1. Data Cleaning Functions\n","\n","def strip_emoji(text):\n","    return emoji.replace_emoji(text, replace='')\n","    # return emoji.get_emoji_regexp().sub(\"\", text)\n","\n","def strip_all_entities(text):\n","    text = re.sub(r'\\r|\\n', ' ', text.lower())\n","    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text)\n","    text = re.sub(r'[^\\x00-\\x7f]', '', text)\n","    banned_list = string.punctuation\n","    table = str.maketrans('', '', banned_list)\n","    text = text.translate(table)\n","    text = ' '.join(word for word in text.split() if word not in stop_words)\n","    return text\n","\n","def clean_hashtags(tweet):\n","    new_tweet = re.sub(r'(\\s+#[\\w-]+)+\\s*$', '', tweet).strip()\n","    new_tweet = re.sub(r'#([\\w-]+)', r'\\1', new_tweet).strip()\n","    return new_tweet\n","\n","def filter_chars(text):\n","    return ' '.join('' if ('$' in word) or ('&' in word) else word for word in text.split())\n","\n","def remove_mult_spaces(text):\n","    return re.sub(r\"\\s\\s+\", \" \", text)\n","\n","def filter_non_english(text):\n","    try:\n","        lang = detect(text)\n","    except LangDetectException:\n","        lang = \"unknown\"\n","    return text if lang == \"en\" else \"\"\n","\n","def expand_contractions(text):\n","    return contractions.fix(text)\n","\n","def remove_numbers(text):\n","    return re.sub(r'\\d+', '', text)\n","\n","def lemmatize(text):\n","    words = word_tokenize(text)\n","    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n","    return ' '.join(lemmatized_words)\n","\n","def remove_short_words(text, min_len=1):\n","    words = text.split()\n","    long_words = [word for word in words if len(word) >= min_len]\n","    return ' '.join(long_words)\n","\n","def replace_elongated_words(text):\n","    regex_pattern = r'\\b(\\w+)((\\w)\\3{2,})(\\w*)\\b'\n","    return re.sub(regex_pattern, r'\\1\\3\\4', text)\n","\n","def remove_repeated_punctuation(text):\n","    return re.sub(r'[\\?\\.\\!]+(?=[\\?\\.\\!])', '', text)\n","\n","def remove_extra_whitespace(text):\n","    return ' '.join(text.split())\n","\n","def remove_url_shorteners(text):\n","    return re.sub(r'(?:http[s]?://)?(?:www\\.)?(?:bit\\.ly|goo\\.gl|t\\.co|tinyurl\\.com|tr\\.im|is\\.gd|cli\\.gs|u\\.nu|url\\.ie|tiny\\.cc|alturl\\.com|ow\\.ly|bit\\.do|adoro\\.to)\\S+', '', text)\n","\n","def remove_spaces_tweets(tweet):\n","    return tweet.strip()\n","\n","def remove_short_tweets(tweet, min_words=1):\n","    words = tweet.split()\n","    return tweet if len(words) >= min_words else \"\"\n","\n","# 2. Main Cleaning Function\n","\n","def clean_tweet(tweet):\n","    tweet = str(tweet).lower()\n","    \n","    tweet = strip_emoji(tweet)\n","    tweet = expand_contractions(tweet)\n","    # tweet = filter_non_english(tweet)\n","    tweet = strip_all_entities(tweet)\n","    tweet = clean_hashtags(tweet)\n","    tweet = filter_chars(tweet)\n","    tweet = remove_mult_spaces(tweet)\n","    tweet = remove_numbers(tweet)\n","    tweet = lemmatize(tweet)\n","    tweet = remove_short_words(tweet)\n","    tweet = replace_elongated_words(tweet)\n","    tweet = remove_repeated_punctuation(tweet)\n","    tweet = remove_extra_whitespace(tweet)\n","    tweet = remove_url_shorteners(tweet)\n","    tweet = remove_spaces_tweets(tweet)\n","    tweet = remove_short_tweets(tweet)\n","    tweet = ' '.join(tweet.split())\n","    return tweet\n","\n","# 3. Data Loading and Saving\n","\n","def load_and_clean_data(data_path, cleaned_data_path):\n","    if os.path.exists(cleaned_data_path):\n","        print(\"Cleaned data file already exists. Loading from file...\")\n","        df = pd.read_csv(cleaned_data_path)\n","    else:\n","        df = pd.read_csv(data_path)\n","        df['text'] = df['text'].fillna('').astype(str)  # Ensure all text entries are strings\n","        df['text_clean'] = [clean_tweet(tweet) for tweet in tqdm(df['text'], desc=\"Cleaning Tweets\")]\n","        df.to_csv(cleaned_data_path, index=False)\n","    return df\n","\n","\n","def clean_data(df):\n","    df['text'] = df['text'].fillna('').astype(str)  # Ensure all text entries are strings\n","    df[\"clean_text\"] = df[\"text\"].progress_apply(clean_tweet)\n","    return df"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ehZ_v2QeFBSm"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 11109/11109 [00:01<00:00, 7119.57it/s] \n","100%|██████████| 16408/16408 [00:01<00:00, 12417.48it/s]\n","100%|██████████| 2473/2473 [00:00<00:00, 9381.70it/s]\n"]}],"source":["df_gn = clean_data(df_gn)\n","df_sf = clean_data(df_sf)\n","df_tw = clean_data(df_tw)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"WOS_5CzeFBSm"},"outputs":[{"name":"stdout","output_type":"stream","text":["Create data path: /Users/zhouyf/Documents/data/majid/drive/MyDrive/project2/data/cleaned_data\n"]}],"source":["if not os.path.exists(config.data_path):\n","    os.makedirs(config.data_path)\n","    print(f\"Create data path: {config.data_path}\")\n","    \n","with open(config.googel_news, 'w' , encoding = 'utf-8') as fp:\n","    json.dump(df_gn.to_dict('records'), fp , ensure_ascii=False, indent=2)\n","\n","with open(config.stack_overflow, 'w' , encoding = 'utf-8') as fp:\n","    json.dump(df_sf.to_dict('records'), fp , ensure_ascii=False, indent=2)\n","\n","with open(config.tweets, 'w' , encoding = 'utf-8') as fp:\n","    json.dump(df_tw.to_dict('records'), fp , ensure_ascii=False, indent=2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#creat labl_map one time and save it as assets (google example)\n","\n","#labl_map = {  item:i for i , item in enumerate(list(set(df['label']))) if item}\n","#inv_lable_map = {item:i for i , item in labl_map.items() }\n","#with open(config.goole_label_map, 'w' , encoding = 'utf-8') as fp:\n","#    json.dump(labl_map, fp , ensure_ascii=False )\n","\n","#with open(config.google_inv_label_map, 'w' , encoding = 'utf-8') as fp:\n","#    json.dump(inv_lable_map, fp , ensure_ascii=False )"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.9.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"}}},"nbformat":4,"nbformat_minor":0}
